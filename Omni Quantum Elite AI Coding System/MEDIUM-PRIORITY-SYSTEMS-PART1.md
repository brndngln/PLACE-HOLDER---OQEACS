# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MEDIUM PRIORITY SYSTEMS (18-27) + FLOWISE AI â€” PART 1
# OMNI QUANTUM ELITE â€” ULTIMATE EDITION
# Systems 18-21: OpenHands, SWE-Agent, Nango, MinIO
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                                              â•‘
â•‘    â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—â–ˆâ–ˆâ•—   â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—         â•‘
â•‘    â–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ•‘    â•šâ•â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—        â•‘
â•‘    â–ˆâ–ˆâ•”â–ˆâ–ˆâ–ˆâ–ˆâ•”â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â–ˆâ–ˆâ–ˆâ–ˆâ•”â–ˆâ–ˆâ•‘       â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•        â•‘
â•‘    â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘       â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—        â•‘
â•‘    â–ˆâ–ˆâ•‘ â•šâ•â• â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘ â•šâ•â• â–ˆâ–ˆâ•‘       â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘        â•‘
â•‘    â•šâ•â•     â•šâ•â•â•šâ•â•â•â•â•â•â•â•šâ•â•â•â•â•â• â•šâ•â• â•šâ•â•â•â•â•â• â•šâ•â•     â•šâ•â•       â•šâ•â•   â•šâ•â•â•šâ•â•â•â•â•â•â•â•šâ•â•  â•šâ•â•        â•‘
â•‘                                                                                              â•‘
â•‘                      "Autonomous Agents. Infinite Integrations. Zero Limits."                 â•‘
â•‘                                                                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SYSTEM 18: OPENHANDS â€” AI CODING AGENT
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                   OPENHANDS ARCHITECTURE                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                             â”‚
â”‚  USER REQUEST                    OPENHANDS CORE                     EXECUTION               â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                     â”€â”€â”€â”€â”€â”€â”€â”€â”€                â”‚
â”‚                                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚  ðŸ’¬ Natural Lang  â”‚          â”‚                               â”‚  â”‚  ðŸ“ File System   â”‚      â”‚
â”‚  â”‚  â€¢ "Build a REST  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚     AGENT CONTROLLER          â”‚â”€â–¶â”‚  â€¢ Read/Write     â”‚      â”‚
â”‚  â”‚    API for..."    â”‚          â”‚                               â”‚  â”‚  â€¢ Create/Delete  â”‚      â”‚
â”‚  â”‚  â€¢ "Fix bug in.." â”‚          â”‚  â€¢ CodeAct Agent (primary)    â”‚  â”‚  â€¢ Navigate dirs  â”‚      â”‚
â”‚  â”‚  â€¢ "Refactor..."  â”‚          â”‚  â€¢ Browsing Agent             â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚  â€¢ Monologue Agent            â”‚                            â”‚
â”‚                                â”‚  â€¢ Delegator Agent            â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚                               â”‚  â”‚  ðŸ–¥ï¸ Terminal       â”‚      â”‚
â”‚  â”‚  ðŸ”— API Triggers  â”‚          â”‚  LLM BACKENDS:                â”‚â”€â–¶â”‚  â€¢ Bash commands  â”‚      â”‚
â”‚  â”‚  â€¢ Gitea webhooks â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚  â€¢ Install deps   â”‚      â”‚
â”‚  â”‚  â€¢ Mattermost bot â”‚          â”‚  â”‚ LiteLLM Gateway â”€â”€â”€â”€â”€â”€â”‚â”€â”€â”€â”‚  â”‚  â€¢ Run tests      â”‚      â”‚
â”‚  â”‚  â€¢ n8n workflows  â”‚          â”‚  â”‚ â€¢ Local: Ollama        â”‚   â”‚  â”‚  â€¢ Git operations â”‚      â”‚
â”‚  â”‚  â€¢ REST endpoint  â”‚          â”‚  â”‚ â€¢ Cloud: Groq/Gemini   â”‚   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚  â”‚ â€¢ Aggregator: OpenRouterâ”‚   â”‚                            â”‚
â”‚                                â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚                               â”‚  â”‚  ðŸŒ Browser        â”‚      â”‚
â”‚  â”‚  ðŸ“‹ Plane Issues  â”‚          â”‚  SANDBOXED EXECUTION:         â”‚â”€â–¶â”‚  â€¢ Web research   â”‚      â”‚
â”‚  â”‚  â€¢ Auto-assigned  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚  â€¢ Doc lookup     â”‚      â”‚
â”‚  â”‚  â€¢ Priority-based â”‚          â”‚  â”‚ Docker-in-Docker       â”‚   â”‚  â”‚  â€¢ API docs       â”‚      â”‚
â”‚  â”‚  â€¢ Sprint tasks   â”‚          â”‚  â”‚ â€¢ Isolated workspace   â”‚   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚  â”‚ â€¢ Per-task containers   â”‚   â”‚                            â”‚
â”‚                                â”‚  â”‚ â€¢ Resource limits       â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚                                â”‚  â”‚ â€¢ Auto-cleanup          â”‚   â”‚  â”‚  ðŸ“Š Langfuse       â”‚      â”‚
â”‚                                â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚â”€â–¶â”‚  â€¢ Trace all runs  â”‚      â”‚
â”‚                                â”‚                               â”‚  â”‚  â€¢ Cost tracking   â”‚      â”‚
â”‚                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â€¢ Quality scores  â”‚      â”‚
â”‚                                                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## DOCKER COMPOSE

```yaml
# docker-compose.openhands.yml
version: "3.9"

services:
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # OPENHANDS â€” AI CODING AGENT
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  openhands:
    image: docker.all-hands.dev/all-hands-ai/openhands:latest
    container_name: omni-quantum-openhands
    ports:
      - "3100:3000"
    environment:
      # â”€â”€ LLM Configuration (via LiteLLM Gateway) â”€â”€
      LLM_MODEL: "litellm/ollama/deepseek-coder-v2"
      LLM_API_KEY: "${LITELLM_API_KEY}"
      LLM_BASE_URL: "http://litellm:4000/v1"
      LLM_EMBEDDING_MODEL: "litellm/ollama/nomic-embed-text"

      # â”€â”€ Workspace â”€â”€
      WORKSPACE_BASE: "/opt/workspace"
      WORKSPACE_MOUNT_PATH: "${OPENHANDS_WORKSPACE:-/opt/omni-quantum/workspaces/openhands}"
      WORKSPACE_MOUNT_REWRITE: "/opt/workspace"

      # â”€â”€ Sandbox Configuration â”€â”€
      SANDBOX_TYPE: "docker"
      SANDBOX_CONTAINER_IMAGE: "docker.all-hands.dev/all-hands-ai/runtime:latest"
      SANDBOX_USER_ID: 1000
      SANDBOX_TIMEOUT: 300
      SANDBOX_ENABLE_AUTO_LINT: true
      SANDBOX_INIT_PLUGINS: "JupyterRequirement,AgentSkillsRequirement"

      # â”€â”€ Agent Configuration â”€â”€
      DEFAULT_AGENT: "CodeActAgent"
      MAX_ITERATIONS: 100
      MAX_BUDGET_PER_TASK: 0   # Unlimited (routed through Token Infinity)

      # â”€â”€ Observability â”€â”€
      LANGFUSE_PUBLIC_KEY: "${LANGFUSE_PUBLIC_KEY}"
      LANGFUSE_SECRET_KEY: "${LANGFUSE_SECRET_KEY}"
      LANGFUSE_HOST: "http://langfuse:3000"

      # â”€â”€ Security â”€â”€
      JWT_SECRET: "${OPENHANDS_JWT_SECRET}"
      GITHUB_TOKEN: ""  # Not needed â€” uses Gitea

      # â”€â”€ Logging â”€â”€
      LOG_ALL_EVENTS: true
      DEBUG: false
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - openhands_data:/opt/workspace
      - ./config/openhands/config.toml:/app/config.toml:ro
      - ./config/openhands/presets:/app/presets:ro
    depends_on:
      litellm:
        condition: service_healthy
    networks:
      - omni-quantum-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 45s
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: "2.0"
        reservations:
          memory: 1G
          cpus: "0.5"
    labels:
      - "omni.quantum.component=openhands"
      - "omni.quantum.tier=ai-agents"
      - "omni.quantum.system=18"
      - "prometheus.scrape=true"
      - "prometheus.port=3000"
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"

volumes:
  openhands_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${DATA_ROOT:-/opt/omni-quantum/data}/openhands

networks:
  omni-quantum-network:
    external: true
```

## CONFIGURATION

```toml
# config/openhands/config.toml
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# OPENHANDS â€” OMNI QUANTUM ELITE CONFIGURATION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

[core]
workspace_base = "/opt/workspace"
run_as_openhands = true
max_iterations = 100
max_budget_per_task = 0.0
default_agent = "CodeActAgent"
cache_dir = "/tmp/cache"
ssh_hostname = "openhands"

[llm]
model = "litellm/ollama/deepseek-coder-v2"
api_key = "${LITELLM_API_KEY}"
base_url = "http://litellm:4000/v1"
embedding_model = "litellm/ollama/nomic-embed-text"
max_message_chars = 30000
temperature = 0.0
top_p = 0.95
num_retries = 5
retry_min_wait = 3
retry_max_wait = 60
timeout = 600

[llm.fallback]
model = "litellm/groq/llama-3.3-70b-versatile"
api_key = "${LITELLM_API_KEY}"
base_url = "http://litellm:4000/v1"

[sandbox]
type = "docker"
container_image = "docker.all-hands.dev/all-hands-ai/runtime:latest"
user_id = 1000
timeout = 300
enable_auto_lint = true
use_host_network = false
init_plugins = ["JupyterRequirement", "AgentSkillsRequirement"]

[sandbox.resources]
cpus = 2
memory_gb = 4

[security]
enable_security_analyzer = true
confirmation_mode = false
security_analyzer = "invariant"
```

## PYTHON SDK â€” OPENHANDS INTEGRATION CLIENT

```python
# sdk/openhands_client.py
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# OPENHANDS INTEGRATION SDK â€” OMNI QUANTUM ELITE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

"""
Enterprise-grade OpenHands client for the Omni Quantum Elite platform.
Provides programmatic task submission, status monitoring, and result retrieval.
"""

import asyncio
import json
import logging
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from typing import Any, Optional
from urllib.parse import urljoin

import aiohttp

logger = logging.getLogger("omni.quantum.openhands")


class TaskStatus(Enum):
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    TIMEOUT = "timeout"
    CANCELLED = "cancelled"


class AgentType(Enum):
    CODE_ACT = "CodeActAgent"
    BROWSING = "BrowsingAgent"
    MONOLOGUE = "MonologueAgent"
    DELEGATOR = "DelegatorAgent"


@dataclass
class TaskResult:
    task_id: str
    status: TaskStatus
    output: str = ""
    files_modified: list[str] = field(default_factory=list)
    git_diff: str = ""
    iterations_used: int = 0
    cost_estimate: float = 0.0
    duration_seconds: float = 0.0
    error: Optional[str] = None
    created_at: datetime = field(default_factory=datetime.utcnow)


class OpenHandsClient:
    """Async client for OpenHands AI Coding Agent."""

    def __init__(
        self,
        base_url: str = "http://openhands:3000",
        api_key: Optional[str] = None,
        timeout: int = 600,
    ):
        self.base_url = base_url.rstrip("/")
        self.api_key = api_key
        self.timeout = aiohttp.ClientTimeout(total=timeout)
        self._session: Optional[aiohttp.ClientSession] = None

    async def _get_session(self) -> aiohttp.ClientSession:
        if self._session is None or self._session.closed:
            headers = {"Content-Type": "application/json"}
            if self.api_key:
                headers["Authorization"] = f"Bearer {self.api_key}"
            self._session = aiohttp.ClientSession(
                headers=headers, timeout=self.timeout
            )
        return self._session

    async def submit_task(
        self,
        instruction: str,
        agent: AgentType = AgentType.CODE_ACT,
        workspace: Optional[str] = None,
        max_iterations: int = 100,
        git_repo: Optional[str] = None,
        git_branch: str = "main",
    ) -> str:
        """Submit a coding task. Returns task_id."""
        session = await self._get_session()
        payload = {
            "instruction": instruction,
            "agent": agent.value,
            "max_iterations": max_iterations,
        }
        if workspace:
            payload["workspace"] = workspace
        if git_repo:
            payload["git_repo"] = git_repo
            payload["git_branch"] = git_branch

        async with session.post(
            f"{self.base_url}/api/conversations", json=payload
        ) as resp:
            resp.raise_for_status()
            data = await resp.json()
            task_id = data.get("conversation_id", data.get("id"))
            logger.info(f"Task submitted: {task_id}")
            return task_id

    async def get_status(self, task_id: str) -> TaskResult:
        """Get current task status and results."""
        session = await self._get_session()
        async with session.get(
            f"{self.base_url}/api/conversations/{task_id}"
        ) as resp:
            resp.raise_for_status()
            data = await resp.json()
            return TaskResult(
                task_id=task_id,
                status=TaskStatus(data.get("status", "pending")),
                output=data.get("output", ""),
                files_modified=data.get("files_modified", []),
                git_diff=data.get("git_diff", ""),
                iterations_used=data.get("iterations", 0),
                duration_seconds=data.get("duration", 0.0),
                error=data.get("error"),
            )

    async def wait_for_completion(
        self, task_id: str, poll_interval: float = 5.0, timeout: float = 3600
    ) -> TaskResult:
        """Poll until task completes or times out."""
        start = asyncio.get_event_loop().time()
        while True:
            result = await self.get_status(task_id)
            if result.status in (
                TaskStatus.COMPLETED,
                TaskStatus.FAILED,
                TaskStatus.TIMEOUT,
                TaskStatus.CANCELLED,
            ):
                return result
            elapsed = asyncio.get_event_loop().time() - start
            if elapsed > timeout:
                result.status = TaskStatus.TIMEOUT
                return result
            await asyncio.sleep(poll_interval)

    async def cancel_task(self, task_id: str) -> bool:
        """Cancel a running task."""
        session = await self._get_session()
        async with session.post(
            f"{self.base_url}/api/conversations/{task_id}/cancel"
        ) as resp:
            return resp.status == 200

    async def close(self):
        if self._session and not self._session.closed:
            await self._session.close()

    async def __aenter__(self):
        return self

    async def __aexit__(self, *args):
        await self.close()
```

## INIT SCRIPT

```bash
#!/usr/bin/env bash
# scripts/init-openhands.sh
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# OPENHANDS INITIALIZATION â€” OMNI QUANTUM ELITE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
set -euo pipefail

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
source "${SCRIPT_DIR}/common.sh"

log_header "SYSTEM 18: OPENHANDS â€” AI CODING AGENT"

# Create directories
ensure_dir "${DATA_ROOT}/openhands"
ensure_dir "${CONFIG_ROOT}/openhands/presets"
ensure_dir "${WORKSPACE_ROOT}/openhands"

# Generate secrets
ensure_secret "OPENHANDS_JWT_SECRET" 64

# Pre-pull sandbox runtime image
log_info "Pulling OpenHands sandbox runtime..."
docker pull docker.all-hands.dev/all-hands-ai/runtime:latest 2>/dev/null || true

# Create Gitea webhook preset
cat > "${CONFIG_ROOT}/openhands/presets/gitea-webhook.json" << 'PRESET'
{
  "name": "Gitea PR Review",
  "agent": "CodeActAgent",
  "instruction_template": "Review the pull request at {repo_url}/pulls/{pr_number}. Check for: 1) Code quality and style, 2) Security vulnerabilities, 3) Performance issues, 4) Test coverage. Provide detailed feedback.",
  "max_iterations": 50,
  "triggers": ["pull_request.opened", "pull_request.synchronize"]
}
PRESET

# Create Mattermost integration preset
cat > "${CONFIG_ROOT}/openhands/presets/mattermost-bot.json" << 'PRESET'
{
  "name": "Mattermost Coding Assistant",
  "agent": "CodeActAgent",
  "instruction_template": "User request from Mattermost: {message}. Work in the repository at {workspace_path}. Complete the task and report back.",
  "max_iterations": 100,
  "response_channel": "dev-updates"
}
PRESET

log_success "OpenHands initialized successfully"
log_info "  â†’ Web UI:     http://localhost:3100"
log_info "  â†’ API:        http://openhands:3000/api"
log_info "  â†’ Workspace:  ${WORKSPACE_ROOT}/openhands"
```

---

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SYSTEM 19: SWE-AGENT â€” AUTONOMOUS SOFTWARE ENGINEER
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                   SWE-AGENT ARCHITECTURE                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                             â”‚
â”‚  ISSUE INPUT                     SWE-AGENT CORE                     OUTPUT                  â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                     â”€â”€â”€â”€â”€â”€                  â”‚
â”‚                                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚  ðŸ› Gitea Issues  â”‚          â”‚                               â”‚  â”‚  ðŸ“ Patches       â”‚      â”‚
â”‚  â”‚  â€¢ Bug reports    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚     AGENT-COMPUTER INTERFACE  â”‚â”€â–¶â”‚  â€¢ Git commits    â”‚      â”‚
â”‚  â”‚  â€¢ Feature reqs   â”‚          â”‚            (ACI)              â”‚  â”‚  â€¢ Pull requests  â”‚      â”‚
â”‚  â”‚  â€¢ Refactor tasks â”‚          â”‚                               â”‚  â”‚  â€¢ Branch pushes  â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                â”‚  â”‚ SEARCH  â”‚ â”‚ EDIT        â”‚ â”‚                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚  â”‚ â€¢ find  â”‚ â”‚ â€¢ open      â”‚ â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚  ðŸ“‹ Plane Tasks   â”‚          â”‚  â”‚ â€¢ grep  â”‚ â”‚ â€¢ edit      â”‚ â”‚  â”‚  ðŸ“Š Reports       â”‚      â”‚
â”‚  â”‚  â€¢ Sprint items   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  â”‚ â€¢ tree  â”‚ â”‚ â€¢ insert    â”‚ â”‚â”€â–¶â”‚  â€¢ Success/fail   â”‚      â”‚
â”‚  â”‚  â€¢ Auto-assigned  â”‚          â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â€¢ replace   â”‚ â”‚  â”‚  â€¢ Files changed  â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚  â€¢ Test results   â”‚      â”‚
â”‚                                â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚  â”‚ NAVIGATEâ”‚ â”‚ EXECUTE     â”‚ â”‚                            â”‚
â”‚  â”‚  ðŸ”„ n8n Workflows â”‚          â”‚  â”‚ â€¢ cd    â”‚ â”‚ â€¢ bash      â”‚ â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚  â€¢ Scheduled runs â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  â”‚ â€¢ ls    â”‚ â”‚ â€¢ python    â”‚ â”‚  â”‚  ðŸ’¬ Mattermost     â”‚      â”‚
â”‚  â”‚  â€¢ Event triggers â”‚          â”‚  â”‚ â€¢ pwd   â”‚ â”‚ â€¢ test      â”‚ â”‚â”€â–¶â”‚  â€¢ Status updates â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚  â€¢ PR links       â”‚      â”‚
â”‚                                â”‚                               â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                â”‚  LLM: LiteLLM â†’ Ollama/Groq  â”‚                            â”‚
â”‚                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## DOCKER COMPOSE

```yaml
# docker-compose.swe-agent.yml
version: "3.9"

services:
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # SWE-AGENT â€” AUTONOMOUS SOFTWARE ENGINEER
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  swe-agent:
    build:
      context: ./build/swe-agent
      dockerfile: Dockerfile
    container_name: omni-quantum-swe-agent
    ports:
      - "3101:8000"
    environment:
      # â”€â”€ LLM (via Token Infinity / LiteLLM) â”€â”€
      SWE_AGENT_MODEL: "litellm/ollama/deepseek-coder-v2"
      LITELLM_API_KEY: "${LITELLM_API_KEY}"
      LITELLM_BASE_URL: "http://litellm:4000/v1"

      # â”€â”€ Repository Access (Gitea) â”€â”€
      GITEA_URL: "http://gitea:3000"
      GITEA_TOKEN: "${GITEA_ADMIN_TOKEN}"
      DEFAULT_GIT_USER: "swe-agent"
      DEFAULT_GIT_EMAIL: "swe-agent@omni-quantum.local"

      # â”€â”€ Execution â”€â”€
      MAX_COST: 0           # Unlimited via Token Infinity
      PER_INSTANCE_COST_LIMIT: 0
      TIMEOUT: 600
      MAX_RETRIES: 3

      # â”€â”€ Observability â”€â”€
      LANGFUSE_PUBLIC_KEY: "${LANGFUSE_PUBLIC_KEY}"
      LANGFUSE_SECRET_KEY: "${LANGFUSE_SECRET_KEY}"
      LANGFUSE_HOST: "http://langfuse:3000"

      # â”€â”€ Database â”€â”€
      DATABASE_URL: "postgresql://sweagent:${SWE_AGENT_DB_PASSWORD}@postgres:5432/sweagent"
      REDIS_URL: "redis://:${REDIS_PASSWORD}@redis:6379/5"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - swe_agent_data:/app/data
      - swe_agent_repos:/app/repos
      - ./config/swe-agent/config.yaml:/app/config.yaml:ro
      - ./config/swe-agent/templates:/app/templates:ro
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      litellm:
        condition: service_healthy
    networks:
      - omni-quantum-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: "2.0"
        reservations:
          memory: 1G
    labels:
      - "omni.quantum.component=swe-agent"
      - "omni.quantum.tier=ai-agents"
      - "omni.quantum.system=19"
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"

  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # SWE-AGENT WORKER â€” Background task processor
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  swe-agent-worker:
    build:
      context: ./build/swe-agent
      dockerfile: Dockerfile
    container_name: omni-quantum-swe-agent-worker
    command: ["python", "-m", "celery", "-A", "worker", "worker", "--loglevel=info", "--concurrency=2"]
    environment:
      SWE_AGENT_MODEL: "litellm/ollama/deepseek-coder-v2"
      LITELLM_API_KEY: "${LITELLM_API_KEY}"
      LITELLM_BASE_URL: "http://litellm:4000/v1"
      GITEA_URL: "http://gitea:3000"
      GITEA_TOKEN: "${GITEA_ADMIN_TOKEN}"
      DATABASE_URL: "postgresql://sweagent:${SWE_AGENT_DB_PASSWORD}@postgres:5432/sweagent"
      REDIS_URL: "redis://:${REDIS_PASSWORD}@redis:6379/5"
      LANGFUSE_PUBLIC_KEY: "${LANGFUSE_PUBLIC_KEY}"
      LANGFUSE_SECRET_KEY: "${LANGFUSE_SECRET_KEY}"
      LANGFUSE_HOST: "http://langfuse:3000"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - swe_agent_repos:/app/repos
    depends_on:
      - swe-agent
    networks:
      - omni-quantum-network
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: "2.0"
    labels:
      - "omni.quantum.component=swe-agent-worker"
      - "omni.quantum.tier=ai-agents"
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"

volumes:
  swe_agent_data:
    driver: local
  swe_agent_repos:
    driver: local

networks:
  omni-quantum-network:
    external: true
```

## BUILD DOCKERFILE

```dockerfile
# build/swe-agent/Dockerfile
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SWE-AGENT â€” CUSTOM BUILD FOR OMNI QUANTUM ELITE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FROM python:3.12-slim AS base

ENV PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1 \
    PIP_NO_CACHE_DIR=1 \
    PIP_DISABLE_PIP_VERSION_CHECK=1

RUN apt-get update && apt-get install -y --no-install-recommends \
    git curl docker.io jq && \
    rm -rf /var/lib/apt/lists/*

WORKDIR /app

# Install SWE-Agent from source
RUN pip install swe-agent[all] celery[redis] \
    fastapi uvicorn httpx langfuse psycopg2-binary

COPY config.yaml /app/config.yaml
COPY templates/ /app/templates/
COPY entrypoint.sh /app/entrypoint.sh
RUN chmod +x /app/entrypoint.sh

EXPOSE 8000

ENTRYPOINT ["/app/entrypoint.sh"]
CMD ["uvicorn", "api:app", "--host", "0.0.0.0", "--port", "8000"]
```

## CONFIGURATION

```yaml
# config/swe-agent/config.yaml
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SWE-AGENT CONFIGURATION â€” OMNI QUANTUM ELITE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

agent:
  model:
    name: "litellm/ollama/deepseek-coder-v2"
    api_key: "${LITELLM_API_KEY}"
    api_base: "http://litellm:4000/v1"
    temperature: 0.0
    top_p: 0.95
    max_tokens: 4096
    per_instance_cost_limit: 0.0  # Unlimited

  config:
    system_template: |
      You are an autonomous software engineer working on the Omni Quantum Elite platform.
      You have access to a sandboxed environment with bash, git, and development tools.
      Your goal: resolve the assigned issue by producing a working patch.
      Always write tests. Always run tests before submitting.
      Follow the project's coding standards and conventions.

  tools:
    - name: "bash"
      enabled: true
    - name: "edit"
      enabled: true
    - name: "search"
      enabled: true
    - name: "git"
      enabled: true

execution:
  timeout: 600
  max_retries: 3
  sandbox:
    type: "docker"
    image: "python:3.12-slim"
    memory_limit: "2g"
    cpu_limit: 2
    network_mode: "bridge"

integrations:
  gitea:
    url: "http://gitea:3000"
    auto_create_branch: true
    branch_prefix: "swe-agent/"
    auto_create_pr: true
    pr_template: |
      ## Automated Fix by SWE-Agent

      **Issue:** #{issue_number}
      **Status:** {status}

      ### Changes
      {changes_summary}

      ### Test Results
      ```
      {test_output}
      ```

      ---
      _Generated by SWE-Agent â€¢ Omni Quantum Elite_

  mattermost:
    webhook_url: "http://mattermost:8065/hooks/${MATTERMOST_SWE_WEBHOOK}"
    channel: "dev-updates"
    notify_on: ["start", "success", "failure"]

  langfuse:
    enabled: true
    trace_name: "swe-agent-run"
    tags: ["autonomous", "coding", "omni-quantum"]
```

## PYTHON SDK â€” SWE-AGENT CLIENT

```python
# sdk/swe_agent_client.py
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SWE-AGENT INTEGRATION SDK â€” OMNI QUANTUM ELITE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

"""
Enterprise-grade SWE-Agent client for autonomous issue resolution.
Integrates with Gitea, Plane, and the Token Infinity system.
"""

import asyncio
import logging
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from typing import Any, Optional

import aiohttp

logger = logging.getLogger("omni.quantum.swe_agent")


class RunStatus(Enum):
    QUEUED = "queued"
    CLONING = "cloning"
    RUNNING = "running"
    TESTING = "testing"
    SUBMITTING = "submitting"
    SUCCESS = "success"
    FAILED = "failed"
    TIMEOUT = "timeout"


@dataclass
class SWERunResult:
    run_id: str
    status: RunStatus
    issue_url: str = ""
    pr_url: str = ""
    patch: str = ""
    files_changed: list[str] = field(default_factory=list)
    tests_passed: int = 0
    tests_failed: int = 0
    duration_seconds: float = 0.0
    model_used: str = ""
    error: Optional[str] = None


class SWEAgentClient:
    """Async client for SWE-Agent autonomous software engineer."""

    def __init__(
        self,
        base_url: str = "http://swe-agent:8000",
        timeout: int = 900,
    ):
        self.base_url = base_url.rstrip("/")
        self.timeout = aiohttp.ClientTimeout(total=timeout)
        self._session: Optional[aiohttp.ClientSession] = None

    async def _get_session(self) -> aiohttp.ClientSession:
        if self._session is None or self._session.closed:
            self._session = aiohttp.ClientSession(
                headers={"Content-Type": "application/json"},
                timeout=self.timeout,
            )
        return self._session

    async def resolve_issue(
        self,
        repo_url: str,
        issue_number: int,
        branch: str = "main",
        auto_pr: bool = True,
        max_retries: int = 3,
    ) -> str:
        """Submit an issue for autonomous resolution. Returns run_id."""
        session = await self._get_session()
        payload = {
            "repo_url": repo_url,
            "issue_number": issue_number,
            "base_branch": branch,
            "auto_create_pr": auto_pr,
            "max_retries": max_retries,
        }
        async with session.post(
            f"{self.base_url}/api/runs", json=payload
        ) as resp:
            resp.raise_for_status()
            data = await resp.json()
            run_id = data["run_id"]
            logger.info(f"SWE-Agent run submitted: {run_id} for issue #{issue_number}")
            return run_id

    async def get_run(self, run_id: str) -> SWERunResult:
        """Get run status and results."""
        session = await self._get_session()
        async with session.get(f"{self.base_url}/api/runs/{run_id}") as resp:
            resp.raise_for_status()
            data = await resp.json()
            return SWERunResult(
                run_id=run_id,
                status=RunStatus(data.get("status", "queued")),
                issue_url=data.get("issue_url", ""),
                pr_url=data.get("pr_url", ""),
                patch=data.get("patch", ""),
                files_changed=data.get("files_changed", []),
                tests_passed=data.get("tests_passed", 0),
                tests_failed=data.get("tests_failed", 0),
                duration_seconds=data.get("duration", 0.0),
                model_used=data.get("model", ""),
                error=data.get("error"),
            )

    async def wait_for_completion(
        self, run_id: str, poll_interval: float = 10.0, timeout: float = 3600
    ) -> SWERunResult:
        """Poll until run completes."""
        start = asyncio.get_event_loop().time()
        while True:
            result = await self.get_run(run_id)
            if result.status in (RunStatus.SUCCESS, RunStatus.FAILED, RunStatus.TIMEOUT):
                return result
            if asyncio.get_event_loop().time() - start > timeout:
                result.status = RunStatus.TIMEOUT
                return result
            await asyncio.sleep(poll_interval)

    async def close(self):
        if self._session and not self._session.closed:
            await self._session.close()

    async def __aenter__(self):
        return self

    async def __aexit__(self, *args):
        await self.close()
```

## INIT SCRIPT

```bash
#!/usr/bin/env bash
# scripts/init-swe-agent.sh
set -euo pipefail

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
source "${SCRIPT_DIR}/common.sh"

log_header "SYSTEM 19: SWE-AGENT â€” AUTONOMOUS SOFTWARE ENGINEER"

ensure_dir "${DATA_ROOT}/swe-agent"
ensure_dir "${CONFIG_ROOT}/swe-agent/templates"
ensure_dir "${BUILD_ROOT}/swe-agent"

ensure_secret "SWE_AGENT_DB_PASSWORD" 32

# Create database
create_postgres_db "sweagent" "sweagent" "${SWE_AGENT_DB_PASSWORD}"

# Create entrypoint
cat > "${BUILD_ROOT}/swe-agent/entrypoint.sh" << 'EOF'
#!/bin/bash
set -e
echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
echo "â•‘  SWE-AGENT â€” OMNI QUANTUM ELITE                        â•‘"
echo "â•‘  Autonomous Software Engineer                           â•‘"
echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
git config --global user.name "${DEFAULT_GIT_USER:-swe-agent}"
git config --global user.email "${DEFAULT_GIT_EMAIL:-swe-agent@omni-quantum.local}"
exec "$@"
EOF
chmod +x "${BUILD_ROOT}/swe-agent/entrypoint.sh"

log_success "SWE-Agent initialized successfully"
log_info "  â†’ API:      http://localhost:3101"
log_info "  â†’ Database: sweagent@postgres"
```

---

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SYSTEM 20: NANGO â€” API INTEGRATION PLATFORM
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                    NANGO ARCHITECTURE                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                             â”‚
â”‚  EXTERNAL APIs                   NANGO CORE                         INTERNAL SERVICES       â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                         â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€       â”‚
â”‚                                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚ GitHub   â”‚ â”‚ Stripe   â”‚     â”‚                               â”‚  â”‚  n8n Workflows   â”‚      â”‚
â”‚  â”‚ Gmail    â”‚ â”‚ Twilio   â”‚     â”‚     CONNECTION MANAGEMENT     â”‚  â”‚  â€¢ Sync triggers â”‚      â”‚
â”‚  â”‚ HubSpot  â”‚ â”‚ Jira     â”‚â”€â”€â”€â”€â–¶â”‚                               â”‚â”€â–¶â”‚  â€¢ Data mapping  â”‚      â”‚
â”‚  â”‚ Notion   â”‚ â”‚ Discord  â”‚     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚  â€¢ Error handler â”‚      â”‚
â”‚  â”‚ Linear   â”‚ â”‚ Airtable â”‚     â”‚  â”‚ 250+ Pre-built Providers â”‚ â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚  â”‚ â€¢ OAuth 1.0/2.0/2.0c    â”‚ â”‚                            â”‚
â”‚                                â”‚  â”‚ â€¢ API Key auth           â”‚ â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚ â€¢ Basic auth             â”‚ â”‚  â”‚  Custom Scripts   â”‚      â”‚
â”‚  â”‚  OAUTH FLOW             â”‚   â”‚  â”‚ â€¢ Token refresh          â”‚ â”‚  â”‚  â€¢ Transform dataâ”‚      â”‚
â”‚  â”‚                         â”‚   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚â”€â–¶â”‚  â€¢ Validate       â”‚      â”‚
â”‚  â”‚  User â”€â”€â–¶ Provider â”€â”€â–¶  â”‚   â”‚                               â”‚  â”‚  â€¢ Enrich         â”‚      â”‚
â”‚  â”‚  Callback â”€â”€â–¶ Nango â”€â”€â–¶ â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚  â”‚  Token stored encrypted â”‚   â”‚  â”‚ SYNC ENGINE              â”‚ â”‚                            â”‚
â”‚  â”‚                         â”‚   â”‚  â”‚ â€¢ Incremental syncs      â”‚ â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚ â€¢ Full refresh syncs     â”‚ â”‚  â”‚  PostgreSQL       â”‚      â”‚
â”‚                                â”‚  â”‚ â€¢ Webhook listeners      â”‚ â”‚â”€â–¶â”‚  â€¢ Synced records â”‚      â”‚
â”‚                                â”‚  â”‚ â€¢ Rate limit handling    â”‚ â”‚  â”‚  â€¢ Connection dataâ”‚      â”‚
â”‚                                â”‚  â”‚ â€¢ Auto-pagination        â”‚ â”‚  â”‚  â€¢ Audit logs     â”‚      â”‚
â”‚                                â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## DOCKER COMPOSE

```yaml
# docker-compose.nango.yml
version: "3.9"

services:
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # NANGO SERVER â€” API Connection Hub
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  nango-server:
    image: nango/nango-server:hosted
    container_name: omni-quantum-nango-server
    ports:
      - "3103:3003"
    environment:
      # â”€â”€ Database â”€â”€
      NANGO_DATABASE_URL: "postgresql://nango:${NANGO_DB_PASSWORD}@postgres:5432/nango"

      # â”€â”€ Server â”€â”€
      NANGO_SERVER_URL: "http://nango-server:3003"
      NANGO_DASHBOARD_URL: "http://localhost:3103"
      SERVER_PORT: 3003
      NANGO_SERVER_WEBSOCKETS_PATH: ""

      # â”€â”€ Encryption â”€â”€
      NANGO_ENCRYPTION_KEY: "${NANGO_ENCRYPTION_KEY}"
      NANGO_SECRET_KEY: "${NANGO_SECRET_KEY}"
      NANGO_SECRET_KEY_IV: "${NANGO_SECRET_KEY_IV}"

      # â”€â”€ Redis â”€â”€
      NANGO_REDIS_URL: "redis://:${REDIS_PASSWORD}@redis:6379/6"

      # â”€â”€ Auth â”€â”€
      NANGO_ADMIN_KEY: "${NANGO_ADMIN_KEY}"

      # â”€â”€ Logging â”€â”€
      LOG_LEVEL: "info"
      TELEMETRY: "false"

      # â”€â”€ Features â”€â”€
      NANGO_MANAGE_CONNECTION_CONFIGS: "true"
      DEFAULT_GITHUB_CLIENT_ID: ""
      DEFAULT_GITHUB_CLIENT_SECRET: ""
    volumes:
      - nango_data:/app/data
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - omni-quantum-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3003/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: "1.0"
    labels:
      - "omni.quantum.component=nango-server"
      - "omni.quantum.tier=integrations"
      - "omni.quantum.system=20"
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"

  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # NANGO RUNNER â€” Sync Execution Engine
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  nango-runner:
    image: nango/nango-runner:hosted
    container_name: omni-quantum-nango-runner
    environment:
      NANGO_DATABASE_URL: "postgresql://nango:${NANGO_DB_PASSWORD}@postgres:5432/nango"
      NANGO_ENCRYPTION_KEY: "${NANGO_ENCRYPTION_KEY}"
      NANGO_REDIS_URL: "redis://:${REDIS_PASSWORD}@redis:6379/6"
      NANGO_SERVER_URL: "http://nango-server:3003"
      LOG_LEVEL: "info"
      TELEMETRY: "false"
    depends_on:
      nango-server:
        condition: service_healthy
    networks:
      - omni-quantum-network
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: "1.0"
    labels:
      - "omni.quantum.component=nango-runner"
      - "omni.quantum.tier=integrations"
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"

volumes:
  nango_data:
    driver: local

networks:
  omni-quantum-network:
    external: true
```

## PYTHON SDK â€” NANGO CLIENT

```python
# sdk/nango_client.py
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# NANGO INTEGRATION SDK â€” OMNI QUANTUM ELITE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

"""
Unified API integration client via Nango.
Manages OAuth connections, syncs, and proxy requests to 250+ providers.
"""

import logging
from typing import Any, Optional

import aiohttp

logger = logging.getLogger("omni.quantum.nango")


class NangoClient:
    """Async client for Nango API Integration Platform."""

    def __init__(
        self,
        base_url: str = "http://nango-server:3003",
        secret_key: str = "",
    ):
        self.base_url = base_url.rstrip("/")
        self.secret_key = secret_key
        self._session: Optional[aiohttp.ClientSession] = None

    async def _get_session(self) -> aiohttp.ClientSession:
        if self._session is None or self._session.closed:
            self._session = aiohttp.ClientSession(
                headers={
                    "Authorization": f"Bearer {self.secret_key}",
                    "Content-Type": "application/json",
                },
            )
        return self._session

    async def list_connections(self) -> list[dict]:
        """List all active connections."""
        session = await self._get_session()
        async with session.get(f"{self.base_url}/connections") as resp:
            resp.raise_for_status()
            data = await resp.json()
            return data.get("connections", [])

    async def get_connection(
        self, provider_config_key: str, connection_id: str
    ) -> dict:
        """Get connection details including tokens."""
        session = await self._get_session()
        async with session.get(
            f"{self.base_url}/connections/{connection_id}",
            params={"provider_config_key": provider_config_key},
        ) as resp:
            resp.raise_for_status()
            return await resp.json()

    async def proxy_request(
        self,
        method: str,
        endpoint: str,
        provider_config_key: str,
        connection_id: str,
        data: Optional[dict] = None,
        params: Optional[dict] = None,
    ) -> dict:
        """Proxy an API request through Nango (handles auth automatically)."""
        session = await self._get_session()
        headers = {
            "Provider-Config-Key": provider_config_key,
            "Connection-Id": connection_id,
        }
        async with session.request(
            method,
            f"{self.base_url}/proxy{endpoint}",
            headers=headers,
            json=data,
            params=params,
        ) as resp:
            resp.raise_for_status()
            return await resp.json()

    async def trigger_sync(
        self, provider_config_key: str, connection_id: str, sync_name: str
    ) -> dict:
        """Trigger a data sync."""
        session = await self._get_session()
        payload = {
            "provider_config_key": provider_config_key,
            "connection_id": connection_id,
            "sync_name": sync_name,
        }
        async with session.post(
            f"{self.base_url}/syncs/trigger", json=payload
        ) as resp:
            resp.raise_for_status()
            return await resp.json()

    async def get_records(
        self,
        connection_id: str,
        provider_config_key: str,
        model: str,
        cursor: Optional[str] = None,
        limit: int = 100,
    ) -> dict:
        """Get synced records."""
        session = await self._get_session()
        params = {
            "model": model,
            "connection_id": connection_id,
            "provider_config_key": provider_config_key,
            "limit": limit,
        }
        if cursor:
            params["cursor"] = cursor
        async with session.get(
            f"{self.base_url}/records", params=params
        ) as resp:
            resp.raise_for_status()
            return await resp.json()

    async def close(self):
        if self._session and not self._session.closed:
            await self._session.close()

    async def __aenter__(self):
        return self

    async def __aexit__(self, *args):
        await self.close()
```

## INIT SCRIPT

```bash
#!/usr/bin/env bash
# scripts/init-nango.sh
set -euo pipefail

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
source "${SCRIPT_DIR}/common.sh"

log_header "SYSTEM 20: NANGO â€” API INTEGRATION PLATFORM"

ensure_dir "${DATA_ROOT}/nango"
ensure_dir "${CONFIG_ROOT}/nango"

ensure_secret "NANGO_DB_PASSWORD" 32
ensure_secret "NANGO_ENCRYPTION_KEY" 32
ensure_secret "NANGO_SECRET_KEY" 64
ensure_secret "NANGO_SECRET_KEY_IV" 16
ensure_secret "NANGO_ADMIN_KEY" 48

create_postgres_db "nango" "nango" "${NANGO_DB_PASSWORD}"

log_success "Nango initialized successfully"
log_info "  â†’ Dashboard: http://localhost:3103"
log_info "  â†’ API:       http://nango-server:3003"
```

---

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SYSTEM 21: MINIO â€” S3-COMPATIBLE OBJECT STORAGE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                     MINIO ARCHITECTURE                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                             â”‚
â”‚  CLIENTS                         MINIO CLUSTER                      STORAGE TIERS           â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€                         â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€           â”‚
â”‚                                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚  ðŸ“¦ S3 API        â”‚          â”‚                               â”‚  â”‚  ðŸ”¥ HOT TIER      â”‚      â”‚
â”‚  â”‚  â€¢ AWS SDK        â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚     MINIO GATEWAY             â”‚  â”‚  â€¢ NVMe/SSD       â”‚      â”‚
â”‚  â”‚  â€¢ mc CLI         â”‚          â”‚                               â”‚  â”‚  â€¢ Frequent access â”‚      â”‚
â”‚  â”‚  â€¢ rclone         â”‚          â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚  â”‚ LOAD BALANCER            â”‚ â”‚                            â”‚
â”‚                                â”‚  â”‚ (Built-in / Traefik)     â”‚ â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚  â„ï¸ COLD TIER      â”‚      â”‚
â”‚  â”‚  ðŸ§  AI Services   â”‚          â”‚          â”‚         â”‚          â”‚  â”‚  â€¢ HDD             â”‚      â”‚
â”‚  â”‚  â€¢ Model weights  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â” â”Œâ”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚  â”‚  â€¢ Archives        â”‚      â”‚
â”‚  â”‚  â€¢ Training data  â”‚          â”‚  â”‚ MINIO     â”‚ â”‚ MINIO     â”‚â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚  â”‚  â€¢ Embeddings     â”‚          â”‚  â”‚ NODE 1    â”‚ â”‚ NODE 2    â”‚â”‚                            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚  â”‚ (Primary) â”‚ â”‚ (Standby) â”‚â”‚                            â”‚
â”‚                                â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚                               â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚  ðŸ’¾ Backups       â”‚          â”‚  FEATURES:                    â”‚  â”‚  BUCKETS:          â”‚      â”‚
â”‚  â”‚  â€¢ DB snapshots   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  â€¢ Erasure coding (EC:4)     â”‚  â”‚  â€¢ models          â”‚      â”‚
â”‚  â”‚  â€¢ Config exports â”‚          â”‚  â€¢ Bitrot protection          â”‚  â”‚  â€¢ datasets        â”‚      â”‚
â”‚  â”‚  â€¢ Git bundles    â”‚          â”‚  â€¢ Versioning + Locking      â”‚  â”‚  â€¢ backups         â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚  â€¢ Bucket notifications       â”‚  â”‚  â€¢ artifacts       â”‚      â”‚
â”‚                                â”‚  â€¢ S3 Select queries          â”‚  â”‚  â€¢ uploads         â”‚      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚  â€¢ Object lifecycle           â”‚  â”‚  â€¢ logs            â”‚      â”‚
â”‚  â”‚  ðŸ“Š Analytics     â”‚          â”‚  â€¢ Replication                â”‚  â”‚  â€¢ training-data   â”‚      â”‚
â”‚  â”‚  â€¢ Data lakes     â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  â€¢ Prometheus metrics         â”‚  â”‚  â€¢ embeddings      â”‚      â”‚
â”‚  â”‚  â€¢ CSV/Parquet    â”‚          â”‚  â€¢ Audit logging              â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â”‚                                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## DOCKER COMPOSE

```yaml
# docker-compose.minio.yml
version: "3.9"

services:
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # MINIO â€” S3-Compatible Object Storage
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  minio:
    image: quay.io/minio/minio:latest
    container_name: omni-quantum-minio
    command: server /data --console-address ":9001"
    ports:
      - "9000:9000"     # S3 API
      - "9001:9001"     # Web Console
    environment:
      MINIO_ROOT_USER: "${MINIO_ROOT_USER}"
      MINIO_ROOT_PASSWORD: "${MINIO_ROOT_PASSWORD}"

      # â”€â”€ Identity & Access â”€â”€
      MINIO_BROWSER: "on"
      MINIO_BROWSER_REDIRECT_URL: "http://localhost:9001"

      # â”€â”€ Region â”€â”€
      MINIO_SITE_REGION: "us-east-1"
      MINIO_SITE_NAME: "omni-quantum"

      # â”€â”€ Monitoring â”€â”€
      MINIO_PROMETHEUS_AUTH_TYPE: "public"
      MINIO_PROMETHEUS_URL: "http://prometheus:9090"
      MINIO_PROMETHEUS_JOB_ID: "minio-metrics"

      # â”€â”€ Notifications (Mattermost via webhook) â”€â”€
      MINIO_NOTIFY_WEBHOOK_ENABLE_PRIMARY: "on"
      MINIO_NOTIFY_WEBHOOK_ENDPOINT_PRIMARY: "http://n8n:5678/webhook/minio-events"
      MINIO_NOTIFY_WEBHOOK_QUEUE_DIR_PRIMARY: "/data/.minio/events"

      # â”€â”€ Logging â”€â”€
      MINIO_AUDIT_WEBHOOK_ENABLE: "on"
      MINIO_AUDIT_WEBHOOK_ENDPOINT: "http://n8n:5678/webhook/minio-audit"

      # â”€â”€ Healing â”€â”€
      MINIO_HEAL_INTERVAL: "30m"

      # â”€â”€ Compression â”€â”€
      MINIO_COMPRESSION_ENABLE: "on"
      MINIO_COMPRESSION_EXTENSIONS: ".txt,.log,.csv,.json,.xml,.html,.md,.yaml,.yml"
      MINIO_COMPRESSION_MIME_TYPES: "text/*,application/json,application/xml"
    volumes:
      - minio_data:/data
      - ./config/minio/certs:/root/.minio/certs:ro
    networks:
      - omni-quantum-network
    healthcheck:
      test: ["CMD", "mc", "ready", "local"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: "2.0"
        reservations:
          memory: 512M
    labels:
      - "omni.quantum.component=minio"
      - "omni.quantum.tier=storage"
      - "omni.quantum.system=21"
      - "prometheus.scrape=true"
      - "prometheus.port=9000"
      - "prometheus.path=/minio/v2/metrics/cluster"
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"

  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # MINIO CLIENT â€” Initialization & Management
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  minio-init:
    image: quay.io/minio/mc:latest
    container_name: omni-quantum-minio-init
    entrypoint: /bin/sh
    command: |
      -c '
      echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
      echo "  MINIO BUCKET INITIALIZATION"
      echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

      # Wait for MinIO
      until mc alias set oqe http://minio:9000 ${MINIO_ROOT_USER} ${MINIO_ROOT_PASSWORD} 2>/dev/null; do
        echo "Waiting for MinIO..."
        sleep 3
      done

      # Create core buckets
      BUCKETS="models datasets backups artifacts uploads logs training-data embeddings documents temp"
      for bucket in $BUCKETS; do
        mc mb --ignore-existing oqe/$bucket
        echo "  âœ“ Bucket: $bucket"
      done

      # Set lifecycle policies
      mc ilm rule add oqe/temp --expire-days 7 --noncurrent-expire-days 1
      mc ilm rule add oqe/logs --expire-days 90 --noncurrent-expire-days 30
      mc ilm rule add oqe/backups --noncurrent-expire-days 30

      # Enable versioning on critical buckets
      mc version enable oqe/models
      mc version enable oqe/backups
      mc version enable oqe/documents

      # Set public read on artifacts (for CI/CD downloads)
      mc anonymous set download oqe/artifacts

      # Create service accounts
      mc admin user add oqe ai-service "${MINIO_AI_PASSWORD}" 2>/dev/null || true
      mc admin user add oqe backup-service "${MINIO_BACKUP_PASSWORD}" 2>/dev/null || true

      # Apply policies
      mc admin policy attach oqe readwrite --user ai-service
      mc admin policy attach oqe readwrite --user backup-service

      # Set bucket notifications for n8n webhooks
      mc event add oqe/uploads arn:minio:sqs::PRIMARY:webhook --event put,delete

      echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
      echo "  âœ… MINIO INITIALIZATION COMPLETE"
      echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
      '
    environment:
      MINIO_ROOT_USER: "${MINIO_ROOT_USER}"
      MINIO_ROOT_PASSWORD: "${MINIO_ROOT_PASSWORD}"
      MINIO_AI_PASSWORD: "${MINIO_AI_PASSWORD}"
      MINIO_BACKUP_PASSWORD: "${MINIO_BACKUP_PASSWORD}"
    depends_on:
      minio:
        condition: service_healthy
    networks:
      - omni-quantum-network

volumes:
  minio_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${DATA_ROOT:-/opt/omni-quantum/data}/minio

networks:
  omni-quantum-network:
    external: true
```

## PYTHON SDK â€” MINIO CLIENT

```python
# sdk/minio_client.py
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MINIO S3 STORAGE SDK â€” OMNI QUANTUM ELITE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

"""
Enterprise S3-compatible storage client with bucket management,
presigned URLs, multipart uploads, and lifecycle automation.
"""

import io
import json
import logging
from datetime import timedelta
from typing import Any, BinaryIO, Iterator, Optional

from minio import Minio
from minio.error import S3Error

logger = logging.getLogger("omni.quantum.minio")


class OQEStorageClient:
    """Unified S3 storage client for Omni Quantum Elite."""

    # Pre-defined bucket registry
    BUCKETS = {
        "models": "AI model weights and checkpoints",
        "datasets": "Training and evaluation datasets",
        "backups": "System backups and snapshots",
        "artifacts": "Build artifacts and releases",
        "uploads": "User uploads and attachments",
        "logs": "Application and audit logs",
        "training-data": "ML training data pipelines",
        "embeddings": "Vector embeddings cache",
        "documents": "Documents and reports",
        "temp": "Temporary files (auto-expire 7d)",
    }

    def __init__(
        self,
        endpoint: str = "minio:9000",
        access_key: str = "",
        secret_key: str = "",
        secure: bool = False,
        region: str = "us-east-1",
    ):
        self.client = Minio(
            endpoint,
            access_key=access_key,
            secret_key=secret_key,
            secure=secure,
            region=region,
        )

    def upload_file(
        self,
        bucket: str,
        object_name: str,
        file_path: str,
        content_type: str = "application/octet-stream",
        metadata: Optional[dict] = None,
    ) -> str:
        """Upload a file to a bucket. Returns the object URL."""
        self.client.fput_object(
            bucket,
            object_name,
            file_path,
            content_type=content_type,
            metadata=metadata,
        )
        logger.info(f"Uploaded {object_name} to {bucket}")
        return f"s3://{bucket}/{object_name}"

    def upload_bytes(
        self,
        bucket: str,
        object_name: str,
        data: bytes,
        content_type: str = "application/octet-stream",
        metadata: Optional[dict] = None,
    ) -> str:
        """Upload bytes directly to a bucket."""
        stream = io.BytesIO(data)
        self.client.put_object(
            bucket,
            object_name,
            stream,
            length=len(data),
            content_type=content_type,
            metadata=metadata,
        )
        return f"s3://{bucket}/{object_name}"

    def download_file(self, bucket: str, object_name: str, file_path: str) -> str:
        """Download an object to a local file."""
        self.client.fget_object(bucket, object_name, file_path)
        return file_path

    def get_bytes(self, bucket: str, object_name: str) -> bytes:
        """Download object as bytes."""
        response = self.client.get_object(bucket, object_name)
        try:
            return response.read()
        finally:
            response.close()
            response.release_conn()

    def get_presigned_url(
        self,
        bucket: str,
        object_name: str,
        expires: timedelta = timedelta(hours=1),
        method: str = "GET",
    ) -> str:
        """Generate a presigned URL for temporary access."""
        if method == "PUT":
            return self.client.presigned_put_object(bucket, object_name, expires)
        return self.client.presigned_get_object(bucket, object_name, expires)

    def list_objects(
        self, bucket: str, prefix: str = "", recursive: bool = True
    ) -> Iterator[dict]:
        """List objects in a bucket with optional prefix filter."""
        for obj in self.client.list_objects(bucket, prefix=prefix, recursive=recursive):
            yield {
                "name": obj.object_name,
                "size": obj.size,
                "last_modified": obj.last_modified,
                "etag": obj.etag,
                "content_type": obj.content_type,
            }

    def delete_object(self, bucket: str, object_name: str) -> None:
        """Delete a single object."""
        self.client.remove_object(bucket, object_name)
        logger.info(f"Deleted {object_name} from {bucket}")

    def upload_json(
        self, bucket: str, object_name: str, data: Any, metadata: Optional[dict] = None
    ) -> str:
        """Convenience: upload a JSON-serializable object."""
        json_bytes = json.dumps(data, default=str, indent=2).encode("utf-8")
        return self.upload_bytes(
            bucket, object_name, json_bytes,
            content_type="application/json", metadata=metadata,
        )

    def download_json(self, bucket: str, object_name: str) -> Any:
        """Convenience: download and parse a JSON object."""
        return json.loads(self.get_bytes(bucket, object_name))

    def get_bucket_size(self, bucket: str) -> dict:
        """Calculate total bucket size and object count."""
        total_size = 0
        total_objects = 0
        for obj in self.client.list_objects(bucket, recursive=True):
            total_size += obj.size or 0
            total_objects += 1
        return {
            "bucket": bucket,
            "total_size_bytes": total_size,
            "total_size_human": self._human_size(total_size),
            "total_objects": total_objects,
        }

    @staticmethod
    def _human_size(num: int) -> str:
        for unit in ("B", "KB", "MB", "GB", "TB"):
            if abs(num) < 1024.0:
                return f"{num:.1f} {unit}"
            num /= 1024.0
        return f"{num:.1f} PB"
```

## INIT SCRIPT

```bash
#!/usr/bin/env bash
# scripts/init-minio.sh
set -euo pipefail

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
source "${SCRIPT_DIR}/common.sh"

log_header "SYSTEM 21: MINIO â€” S3-COMPATIBLE OBJECT STORAGE"

ensure_dir "${DATA_ROOT}/minio"
ensure_dir "${CONFIG_ROOT}/minio/certs"

ensure_secret "MINIO_ROOT_USER" 20
ensure_secret "MINIO_ROOT_PASSWORD" 40
ensure_secret "MINIO_AI_PASSWORD" 32
ensure_secret "MINIO_BACKUP_PASSWORD" 32

log_success "MinIO initialized successfully"
log_info "  â†’ S3 API:    http://localhost:9000"
log_info "  â†’ Console:   http://localhost:9001"
log_info "  â†’ Buckets:   models, datasets, backups, artifacts, uploads, logs, training-data, embeddings, documents, temp"
```
